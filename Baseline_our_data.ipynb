{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import pickle\n",
    "\n",
    "from utils import read_jsonl, continuous_string, label_distribution\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments, Trainer, pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read NER data\n",
    "def read_universal_NER(file_path):\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as infile:\n",
    "        # Split into lines\n",
    "        lines = infile.readlines()\n",
    "\n",
    "        # Define lists to store data \n",
    "        sentences = []\n",
    "        labels = []\n",
    "        current_sentence = []\n",
    "        current_labels = []\n",
    "\n",
    "        # Iterate over lines\n",
    "        for line in lines:\n",
    "\n",
    "            line = line.strip() # Remove whitespace\n",
    "            if not line: # Skip empty lines\n",
    "                continue\n",
    "\n",
    "            # Check if line starts with sentence ID\n",
    "            if line.startswith('# sent_id'):\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    labels.append(current_labels)\n",
    "                current_sentence = []\n",
    "                current_labels = []\n",
    "\n",
    "            # Check for token lines\n",
    "            elif not line.startswith(\"#\"):\n",
    "                parts = line.strip().split('\\t')\n",
    "                current_sentence.append(parts[1])\n",
    "                current_labels.append(parts[2])\n",
    "\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "            labels.append(current_labels)\n",
    "\n",
    "    # Flatten lists\n",
    "    #sentences = sum(sentences, [])\n",
    "    #labels = sum(labels, [])\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents, test_labels = read_universal_NER('train_dev_test_sets/test.iob2')\n",
    "train_sents, train_labels = read_universal_NER('train_dev_test_sets/train.iob2')\n",
    "dev_sents, dev_labels = read_universal_NER('train_dev_test_sets/dev.iob2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to process data\n",
    "def preprocess_data(sents, labels):\n",
    "    # Flatten the list of lists\n",
    "    flat_data = [word for sublist in sents for word in sublist]\n",
    "    flat_labels = [label for sublist in labels for label in sublist]\n",
    "\n",
    "    # Join the words to form a single string\n",
    "    text = ' '.join(flat_data)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Split the sentences into lists of words\n",
    "    split_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Align labels to the split sentences\n",
    "    split_labels = []\n",
    "    label_index = 0\n",
    "    for sentence in split_sentences:\n",
    "        sentence_labels = []\n",
    "        for _ in sentence:\n",
    "            if label_index < len(flat_labels):\n",
    "                sentence_labels.append(flat_labels[label_index])\n",
    "                label_index += 1\n",
    "        split_labels.append(sentence_labels)\n",
    "    \n",
    "    return split_sentences, split_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_sents, processed_test_labels = preprocess_data(test_sents, test_labels)\n",
    "processed_train_sents, processed_train_labels = preprocess_data(train_sents, train_labels)\n",
    "processed_dev_sents, processed_dev_labels = preprocess_data(dev_sents, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flatten the list of lists to get a single list of words\n",
    "# flat_test_data = [word for sublist in test_sents for word in sublist]\n",
    "# flat_test_labels = [label for sublist in test_labels for label in sublist]\n",
    "\n",
    "# # Join the words to form a single string for sentence tokenization\n",
    "# text = ' '.join(flat_test_data)\n",
    "\n",
    "# # Tokenize the text into sentences\n",
    "# sentences = sent_tokenize(text)\n",
    "\n",
    "# # Split the sentences into lists of words\n",
    "# test_sents_split = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flatten the list of lists to get a single list of words\n",
    "# flat_train_data = [word for sublist in train_sents for word in sublist]\n",
    "# flat_train_labels = [label for sublist in train_labels for label in sublist]\n",
    "\n",
    "# # Join the words to form a single string for sentence tokenization\n",
    "# text = ' '.join(flat_train_data)\n",
    "\n",
    "# # Tokenize the text into sentences\n",
    "# sentences = sent_tokenize(text)\n",
    "\n",
    "# # Split the sentences into lists of words\n",
    "# train_sents_split = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flatten the list of lists to get a single list of words\n",
    "# flat_dev_data = [word for sublist in dev_sents for word in sublist]\n",
    "# flat_dev_labels = [label for sublist in dev_labels for label in sublist]\n",
    "\n",
    "# # Join the words to form a single string for sentence tokenization\n",
    "# text = ' '.join(flat_dev_data)\n",
    "\n",
    "# # Tokenize the text into sentences\n",
    "# sentences = sent_tokenize(text)\n",
    "\n",
    "# # Split the sentences into lists of words\n",
    "# dev_sents_split = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_split_labels = []\n",
    "# label_index = 0\n",
    "# for sentence in test_sents_split:\n",
    "#     sentence_labels = []\n",
    "#     for _ in sentence:\n",
    "#         if label_index < len(flat_test_labels):\n",
    "#             sentence_labels.append(flat_test_labels[label_index])\n",
    "#             label_index += 1\n",
    "#     test_split_labels.append(sentence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_split_labels = []\n",
    "# label_index = 0\n",
    "# for sentence in train_sents_split:\n",
    "#     sentence_labels = []\n",
    "#     for _ in sentence:\n",
    "#         if label_index < len(flat_train_labels):\n",
    "#             sentence_labels.append(flat_train_labels[label_index])\n",
    "#             label_index += 1\n",
    "#     train_split_labels.append(sentence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_split_labels = []\n",
    "# label_index = 0\n",
    "# for sentence in dev_sents_split:\n",
    "#     sentence_labels = []\n",
    "#     for _ in sentence:\n",
    "#         if label_index < len(flat_dev_labels):\n",
    "#             sentence_labels.append(flat_dev_labels[label_index])\n",
    "#             label_index += 1\n",
    "#     dev_split_labels.append(sentence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'year', 'is', 'an', 'awful', 'long', 'time', 'in', 'football', ',', 'and', 'that', 'has', 'certainly', 'proved', 'the', 'case', 'for', 'Folarin', 'Balogun', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(processed_test_sents[0])\n",
    "print(processed_test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_list_and_labels(strings, labels, num_sublists):\n",
    "#     # Initialize the sublists for strings and labels\n",
    "#     sublists_strings = [[] for _ in range(num_sublists)]\n",
    "#     sublists_labels = [[] for _ in range(num_sublists)]\n",
    "    \n",
    "#     # Distribute the strings and labels into sublists\n",
    "#     for i, (string, label) in enumerate(zip(strings, labels)):\n",
    "#         sublists_strings[i % num_sublists].append(string)\n",
    "#         sublists_labels[i % num_sublists].append(label)\n",
    "    \n",
    "#     return sublists_strings, sublists_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sublists = 800\n",
    "# test_sents_split, test_labels_split = split_list_and_labels(test_sents[0], test_labels[0], num_sublists)\n",
    "# train_sents_split, train_labels_split = split_list_and_labels(train_sents[0], train_labels[0], num_sublists)\n",
    "# dev_sents_split, dev_labels_split = split_list_and_labels(dev_sents[0], dev_labels[0], num_sublists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Mappng\n",
    "label2id = {\n",
    " 'O': 0,\n",
    " 'B-LOC': 1,\n",
    " 'I-LOC': 2,\n",
    " 'B-PER': 3,\n",
    " 'I-PER': 4,\n",
    " 'B-ORG': 5,\n",
    " 'I-ORG': 6,\n",
    " 'B-TIM': 7,\n",
    " 'I-TIM': 8,\n",
    " 'B-MON': 9,\n",
    " 'I-MON': 10,\n",
    " 'B-DAT': 11,\n",
    " 'I-DAT': 12,\n",
    " 'B-PCT': 13,\n",
    " 'I-PCT': 14,\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [key for key in label2id.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_map2id(labels, mapping):\n",
    "    label_ids = []\n",
    "    for sent in labels:\n",
    "        label_id = [mapping.get(label, label) for label in sent]\n",
    "        label_ids.append(label_id)\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_ids = labels_map2id(processed_train_labels, label2id)\n",
    "dev_label_ids = labels_map2id(processed_dev_labels, label2id)\n",
    "test_label_ids = labels_map2id(processed_test_labels, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 5, 0]\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(train_label_ids[0])\n",
    "print(train_split_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\"tokens\": processed_train_sents, \"ner_tags\": train_label_ids})\n",
    "dev_dataset = Dataset.from_dict({\"tokens\": processed_dev_sents, \"ner_tags\": dev_label_ids})\n",
    "test_dataset = Dataset.from_dict({\"tokens\": processed_test_sents, \"ner_tags\": test_label_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 1586\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 446\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 478\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"dev\": dev_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "\n",
    "# Print to verify\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words = True, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "### ÆNDRER ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cb35c4d2ad492dacda613c6dfb206b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1586 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[293], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_datasets \u001b[39m=\u001b[39m raw_datasets\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m      2\u001b[0m     tokenize_and_align_labels,\n\u001b[1;32m      3\u001b[0m     batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      4\u001b[0m     remove_columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mner_tags\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/dataset_dict.py:869\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 869\u001b[0m     {\n\u001b[1;32m    870\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    871\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    872\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    873\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    874\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    875\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    876\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    877\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    878\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    879\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    880\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    881\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    882\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    883\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    884\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    885\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    886\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    887\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    888\u001b[0m         )\n\u001b[1;32m    889\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    890\u001b[0m     }\n\u001b[1;32m    891\u001b[0m )\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/dataset_dict.py:870\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    869\u001b[0m     {\n\u001b[0;32m--> 870\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    871\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    872\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    873\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    874\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    875\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    876\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    877\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    878\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    879\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    880\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    881\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    882\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    883\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    884\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    885\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    886\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    887\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    888\u001b[0m         )\n\u001b[1;32m    889\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    890\u001b[0m     }\n\u001b[1;32m    891\u001b[0m )\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[39mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3543\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3544\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3545\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3548\u001b[0m         batch,\n\u001b[1;32m   3549\u001b[0m         indices,\n\u001b[1;32m   3550\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3551\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3552\u001b[0m     )\n\u001b[1;32m   3553\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3554\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3555\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[292], line 9\u001b[0m, in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, labels \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(all_labels):\n\u001b[1;32m      8\u001b[0m     word_ids \u001b[39m=\u001b[39m tokenized_inputs\u001b[39m.\u001b[39mword_ids(i)\n\u001b[0;32m----> 9\u001b[0m     new_labels\u001b[39m.\u001b[39mappend(align_labels_with_tokens(labels, word_ids))\n\u001b[1;32m     11\u001b[0m tokenized_inputs[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m new_labels\n\u001b[1;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_inputs\n",
      "Cell \u001b[0;32mIn[279], line 8\u001b[0m, in \u001b[0;36malign_labels_with_tokens\u001b[0;34m(labels, word_ids)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m word_id \u001b[39m!=\u001b[39m current_word:\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Start of a new word!\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     current_word \u001b[39m=\u001b[39m word_id\n\u001b[0;32m----> 8\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m \u001b[39mif\u001b[39;00m word_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m labels[word_id]\n\u001b[1;32m      9\u001b[0m     new_labels\u001b[39m.\u001b[39mappend(label)\n\u001b[1;32m     10\u001b[0m \u001b[39melif\u001b[39;00m word_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Special token\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=[\"tokens\", \"ner_tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 478\n",
       "})"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929f76fe998e4179b706f1782f19641f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner-2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dc64d4606943a898661040730a61c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474200691e0d45d1b5abc7469b0604d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08439277857542038, 'eval_precision': 0.875177304964539, 'eval_recall': 0.9046920821114369, 'eval_f1': 0.8896899783705841, 'eval_accuracy': 0.9778323233872823, 'eval_runtime': 3.2035, 'eval_samples_per_second': 139.224, 'eval_steps_per_second': 17.481, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617c41687a6e402c8d0602e3e5ce20c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06450602412223816, 'eval_precision': 0.9194823867721064, 'eval_recall': 0.9376832844574781, 'eval_f1': 0.9284936479128856, 'eval_accuracy': 0.9841988187466442, 'eval_runtime': 1.7732, 'eval_samples_per_second': 251.521, 'eval_steps_per_second': 31.581, 'epoch': 2.0}\n",
      "{'loss': 0.1632, 'grad_norm': 0.39681103825569153, 'learning_rate': 3.2495812395309884e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1367439aa9f544f598848cc9423faaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06387829780578613, 'eval_precision': 0.9284682080924855, 'eval_recall': 0.9420821114369502, 'eval_f1': 0.9352256186317323, 'eval_accuracy': 0.9851959806703996, 'eval_runtime': 1.7597, 'eval_samples_per_second': 253.451, 'eval_steps_per_second': 31.823, 'epoch': 3.0}\n",
      "{'train_runtime': 138.3266, 'train_samples_per_second': 34.397, 'train_steps_per_second': 4.316, 'train_loss': 0.14283090620184663, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=597, training_loss=0.14283090620184663, metrics={'train_runtime': 138.3266, 'train_samples_per_second': 34.397, 'train_steps_per_second': 4.316, 'total_flos': 66586974996204.0, 'train_loss': 0.14283090620184663, 'epoch': 3.0})"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ChristianSneffeFleischer/bert-finetuned-ner-2/commit/23249e4cd671ba9a2df688f9fecaeb4931c1bc74', commit_message='Training complete 3', commit_description='', oid='23249e4cd671ba9a2df688f9fecaeb4931c1bc74', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5049219103b47e9949201be6fcc8477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06387829780578613, 'eval_precision': 0.9284682080924855, 'eval_recall': 0.9420821114369502, 'eval_f1': 0.9352256186317323, 'eval_accuracy': 0.9851959806703996, 'eval_runtime': 1.8961, 'eval_samples_per_second': 235.226, 'eval_steps_per_second': 29.535, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165b5541b8db4d549efeb21bc6929f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions, labels, metrics = trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to label indices\n",
    "predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure predictions is a list of lists\n",
    "if isinstance(predictions, np.ndarray):\n",
    "    if predictions.ndim == 1:\n",
    "        predictions = predictions.tolist()\n",
    "    else:\n",
    "        predictions = [pred.tolist() for pred in predictions]\n",
    "\n",
    "# Convert label indices to label names\n",
    "true_predictions = [\n",
    "    [id2label[p] for p in prediction]\n",
    "    for prediction in predictions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write predictions\n",
    "def write_iob2_predictions(test_sents, predictions, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for i, (sent, prediction) in enumerate(zip(test_sents, predictions)):\n",
    "            outfile.write(f\"# sent_id = test-{i+1:04d}\\n\")\n",
    "            outfile.write(f\"# text = {' '.join(sent)}\\n\")\n",
    "            for j, (word, label) in enumerate(zip(sent, prediction)):\n",
    "                outfile.write(f\"{j+1}\\t{word}\\t{label}\\t-\\t-\\n\")\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the shifted predictions to a file\n",
    "write_iob2_predictions(processed_test_sents, true_predictions, 'test_predictions_our_data.iob2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/myenv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.99479514,\n",
       "  'word': 'Argentina',\n",
       "  'start': 3,\n",
       "  'end': 12}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "model_checkpoint = \"ChristianSneffeFleischer/bert-finetuned-ner\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"In Argentina , beef is revered , respected , and praised .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56941cacf15e8b05765996006082865469347c2b4cdce983108d1335de8b4245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
